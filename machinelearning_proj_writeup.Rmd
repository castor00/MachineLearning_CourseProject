---
title: "Human Activity Recognition"
author: "Antonis Kastor"
date: "Friday, May 22, 2015"
output: html_document
---

## Summary

This work is for the completion of the practical machine learning coursera course. The objective is to build a model that can recognize human activity. The data come from movement sensors attached to participants, who were performing an activity a) in a correct way and b) four wrong ways. The data are cleaned and then divided in a training set and a test set. The training set was used to build the model and the test set to validate the model. The model build is a random forest that predicts with a very good accuracy the activity.   

## Introduction

Huge amounts of data have been available through the use of devices that measure physical activity. The analysis of this data can reveal the activity performed. Human Activity Recognition is the new research filed that does exactly that. This area is well developed now and human activity can be recognized quite well. This work investigates on how well a specific activity is performed.  

This work is for the completion of the practical machine learning coursera course and uses data from Velloso et.al. (2013). The rest of this work describes the steps performed to build the model, presents the model and tests its accuracy. The full code of the project is given in the Appendix.

## The Data

The data come from sensors to participants that were performing one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl. The exercises were performed in five different fashions: one according to the specification (Class A), and four (Classes B to E) in a specified "mistaken" way. The data set is available here (https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv). 

## Data Processing

```{r,echo=FALSE, message=FALSE}
data <- read.csv("pml-training.csv", na.strings=c("NA","#DIV/0!",""))
test.or <- read.csv("pml-testing.csv", na.strings=c("NA","#DIV/0!",""))
library(caret)
```

The data set is consisted of `r dim(data)[1]` observations of `r dim(data)[2]` variables. Observations that contain "NA", "#DIV/0" or are empty are treated as missing values.The data set contains a lot of missing values. Variables that have a high percentage of missing values have nothing to offer in the modelling procedure and are deleted from the data set. 

The following table summarizes the number of the variables by the number of missing values they contain. It can be seen that there are 60 variables that do not contain any missing values. The rest 100 variables contain missing values over than 19,215 of 19,622 total observations.

```{r,echo=FALSE}
na_test = sapply(data, function(x) {sum(is.na(x))})
table(na_test)
na_columns <- names(na_test[na_test > 19215])
data <- data[, !names(data) %in% na_columns]
test.or <- test.or[, !names(test.or) %in% na_columns]
```

Additionally, the first 7 variables are not related to the movement. They are related to the object and the data collection (object name, time etc. ) so they are not useful in a model that tries to predict the movement. The variable number has been reduced to 53. The integer variables are converted to numeric. Now the data are in a shape that we can continue on building the model. 

```{r, echo=FALSE}
numeric.features <- 8:60
data <- data[, numeric.features]
test.or <- test.or[,numeric.features]
for(i in c(1:52)) {data[,i] = as.numeric(as.character(data[,i]))}
for(i in c(1:52)) {test.or[,i] = as.numeric(as.character(test.or[,i]))}
```

Before building the prediction model the data are partitioned in two sets on a 60% - 40% rule. The first set (training) is for building the model and the second (test) for validation.  
```{r}
set.seed(528963)
inTrain <- createDataPartition(y=data$classe, p=0.6, list=FALSE)
training <- data[inTrain,]
testing <- data[-inTrain,]
```

## Building The Model

Purpose of the model is to predict the activity class based on the 52 movement variables. 
Because some of the variables may be not be normally distributed and may trick the machine learning algorithm the data are first pre-processed. The aim of the pre-process is to center and standardize the variables. The pre-process procedure is applied also to the testing subset. 

```{r}
prepr <-preProcess(training[,-53],method=c("center", "scale"))
trainp <- predict(prepr, training[,-53])
trainp$classe <- training$classe

testp <-predict(prepr,testing[,-53])
testorp <- predict(prepr,test.or[,-53])
```

The algorithm selected to built the model is random forest algorithm. Random forests are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees.Random forests give very accurate results, but the results are difficult to interpret. Additionally, they are time consuming and may over fit. 

```{r, cache=TRUE, message=FALSE}
modFit <- train(classe ~., method="rf", data=trainp, trControl=trainControl(method='cv'), number=5, allowParallel=TRUE )
```

```{r, echo=FALSE}
modFit
```

## Accuracy of the model

First, the model is tested on the training set. This estimates the in-sample error.  The accuracy of the model is 1. The prediction matrix shows that it accurately predicts all the classes. 

```{r,message=FALSE}
trPred <- predict(modFit, trainp)
confusionMatrix(trPred, trainp$classe)
```

The model is also tested in the test set. This estimates the out-of-sample error. The accuracy here is expected to be less than the training set but still accurate. I expect not to fall less that 0.98. 

```{r}
tePred <- predict(modFit, testp)
confusionMatrix(tePred, testing$classe)
```

It can be seen from the results that the accuracy is 0.99 and the 95% confidence interval of that is between 0.989 and 0.9933. 

## Results and Discussion 

The model built can predict the class of the exercise performed with about 99% accuracy. It is expected that the model will work very well to the original test set provided. The original test set contains 20 instances and the model should predict almost all of them.  The results are given below. 


```{r}
testPred <- predict(modFit, testorp)
testPred
```

## Bibliography

Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.

Read more: http://groupware.les.inf.puc-rio.br/har#ixzz3awZyeGyZ

## Appendix 

Data and Caret loaded
```{r,eval=FALSE}
data <- read.csv("pml-training.csv", na.strings=c("NA","#DIV/0!",""))
test.or <- read.csv("pml-testing.csv", na.strings=c("NA","#DIV/0!",""))
library(caret)
```

NA Detection and deletion
```{r, eval=FALSE}
na_test = sapply(data, function(x) {sum(is.na(x))})
table(na_test)
na_columns <- names(na_test[na_test > 19215])
data <- data[, !names(data) %in% na_columns]
test.or <- test.or[, !names(test.or) %in% na_columns]
```

Data collection related columns deleted
```{r, eval=FALSE}
numeric.features <- 8:60
data <- data[, numeric.features]
test.or <- test.or[,numeric.features]
for(i in c(1:52)) {data[,i] = as.numeric(as.character(data[,i]))}
for(i in c(1:52)) {test.or[,i] = as.numeric(as.character(test.or[,i]))}
```


data subsetting to training and testing sets. 
```{r, eval=FALSE}
set.seed(528963)
inTrain <- createDataPartition(y=data$classe, p=0.6, list=FALSE)
training <- data[inTrain,]
testing <- data[-inTrain,]
```

Pre-processing
```{r, eval=FALSE}
prepr <-preProcess(training[,-53],method=c("center", "scale"))
trainp <- predict(prepr, training[,-53])
trainp$classe <- training$classe

testp <-predict(prepr,testing[,-53])
testorp <- predict(prepr,test.or[,-53])
```

Model Fitting
```{r, eval=FALSE}
modFit <- train(classe ~., method="rf", data=trainp, trControl=trainControl(method='cv'), number=5, allowParallel=TRUE )
```

Training prediction and confusion matrix
```{r, eval=FALSE}
trPred <- predict(modFit, trainp)
confusionMatrix(trPred, trainp$classe)
```

Tresting prediction and confusion matrix
```{r,eval=FALSE}
tePred <- predict(modFit, testp)
confusionMatrix(tePred, testing$classe)
```

Original test set prediction
```{r,eval=FALSE}
testPred <- predict(modFit, testorp)
```