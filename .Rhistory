testing = adData[trainIndex,]
data(AlzheimerDisease)
adData = data.frame(predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
View(trainIndex)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
View(testing)
View(training)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[-testIndex,]
testing = adData[testIndex,]
View(testing)
View(training)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
library(Hmisc)
library(ggplot2)
summary(concrete)
summary(mixtures)
View(concrete)
View(mixtures)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
View(testing)
qplot(CompressiveStrength, index, color=Cement, data=training)
qplot(CompressiveStrength, Index, color=Cement, data=training)
index <- seq_along(1:nrow(training))
qplot(CompressiveStrength, index, color=Cement, data=training)
qplot(CompressiveStrength, index, color=BlastFurnaceSlag, data=training)
qplot(CompressiveStrength, index, color=Cement, data=training)
qplot(CompressiveStrength, index, color=BlastFurnaceSlag, data=training)
qplot(CompressiveStrength, index, color=FlyAsh, data=training)
qplot(CompressiveStrength, index, color=Water, data=training)
qplot(CompressiveStrength, index, color=Superplasticizer, data=training)
qplot(CompressiveStrength, index, color=CoarseAggegate, data=training)
qplot(CompressiveStrength, index, color=CoarseAggregate, data=training)
qplot(CompressiveStrength, index, color=fineAggregate, data=training)
qplot(CompressiveStrength, index, color=FineAggregate, data=training)
qplot(CompressiveStrength, index, color=Age, data=training)
ggplot(data = training, aes(x = index, y = CompressiveStrength)) + geom_point() +
theme_bw()
qplot(CompressiveStrength, index, color=FlyAsh, data=training)
ggplot(data = training, aes(x = Superplasticizer)) + geom_histogram() + theme_bw()
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
IL_str <- grep("^IL", colnames(training), value = TRUE)
preProc <- preProcess(training[, IL_str], method = "pca", thresh = 0.8)
preProc$rotation
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
library(kernlab)
install.packages("kernlab")
library(kernlab)
data(spam)
inTrain <- createDataPertition(y=spam$type,p=0.75,list=FALSE)
?createDataPartition
library(caret)
inTrain <- createDataPertition(y=spam$type,p=0.75,list=FALSE)
library("caret", lib.loc="~/R/win-library/3.1")
inTrain <- createDataPertition(y=spam$type,p=0.75,list=FALSE)
inTrain <- createDataPartition(y=spam$type,p=0.75,list=FALSE)
training <- spam[intrain]
training <- spam[inTrain]
testing <- spam[-inTrain]
dim(training)
training <- spam[inTrain,]
testing <- spam[-inTrain, ]
dim(training)
set.seed(32343)
modelFit <- train(type ~., data = training, method = "glm")
install.packages('e1071', dependencies=TRUE)
modelFit <- train(type ~., data = training, method = "glm")
warnings()
modelFit
modelFit$finalModel
predictions <- predict(modelFit, newdata=testing)
predictions
confusionMatrix(predictions,testing$type)
set.seed(32323)
folds <- createFolds(y=spam$type, k=10, list=TRUE, returnTrain=TRUE)
sapply(folds,length)
folds[[1]][1:10]
folds[[2]][1:10]
folds[[1]][10:20]
folds[[3]][10:20]
folds
install.packages("ISLR")
library(ISLR)
library(ggplot2)
library(carte)
library(caret)
data(Wage)
summary(Wage)
inTrain <- createDataPartition(y=Wage$wage, p=0.7, list=FALSE)
training <- Wage[inTrain, ]
testing <- Wage[-inTrain, ]
dim(training)
dim(testing)
featurePlot(x=training[ ,c("age","education","jobclass")], y=training$Wage, plot="pairs")
featurePlot(x=training[ ,c("age","education","jobclass")], y=training$wage, plot="pairs")
qplot(age,wage,data=training)
qplot(age,wage,colour=jobclass,data=training)
qq <- qplot(age,wage,colour=education,data=training)
qq + geom_smooth(method="lm", formula=y=x)
qq + geom_smooth(method="lm", formula=y~x)
library(Hmisc)
cutWage <- cut2(training$Wage,g=3)
cutWage <- cut2(training$wage,g=3)
table(cutWage)
p1 <- qplot(cutWage,age, data=training,fill=cutWage, geom=c("boxplot"))
p1
p2 <- qplot(cutWage,age, data=training,fill=cutWage, geom=c("boxplot", "jitter"))
p2
t1<- table(cutWage, training$jobclass)
t1
prop.table(t1,1)
library(kernlab)
data(spam)
intrain <- createDataPartition(y=spam$type, p=0.75, list=FALSE)
training <- spam[inTrain, ]
testing <- spam[-inTrain, ]
hist(training$capitalAve, main="",clab="ave. capital run lenght")
trainCapAve <- training$capitalAve
warnings()
trainCapAves <- (trainCapAve - mean(trainCapAve))/sd(traincapAve)
trainCapAves <- (trainCapAve - mean(trainCapAve))/sd(trainCapAve)
mean(trainCapAves)
sd(trainCapaves)
sd(trainCapAves)
View(spam)
library(caret)
library(kernlab)
data(spam)
intrain <- createDataPartition(y=spam$type, p=0.75,list=FALSE)
training <- spam[inTrain, ]
training <- spam[intrain, ]
testing <- spam[-intrain, ]
M <- abs(cor(training[,-58]))
diag(M) <- 0
which(M>0.8, arr.ind=T)
names(spam)[c(34,32)]
plot(spam[,34],spam[,32])
smallSpam <- spam[,c(34,32)]
View(smallSpam)
prComp <- prcomp(smallSpam)
prComp
prComp$x[,1]
prComp$x
plot(prComp$x[,1],prComp$x[,2])
prComp <- prcomp[log10(spam[,-58]+1)]
preProc <- preProcess(log10(spam[,-58]+1),method="pca",pcaComp=2)
preProc
plot(spamPC[,1],spamPC[,2],col=c(1,2))
data(iris)
library(ggplot2)
names(iris)
tables(iris$Species)
table(iris$Species)
intrain <- createDataPartition(y=iris$Species, p=0.7, list=FALSE)
library(caret)
intrain <- createDataPartition(y=iris$Species, p=0.7, list=FALSE)
training <- iris[inTrain,]
training <- iris[intrain,]
testing <- iris[-intrain,]
dim(training)
dim(testing)
gplot(Petal.Width, Sepal.Width,colour=Species,data=training)
qplot(Petal.Width, Sepal.Width,colour=Species,data=training)
modFit <- train(Species ~., method"rpart, data=training")
modFit <- train(Species ~., method="rpart", data=training)
print(modFit$finalmodel)
modFit <- train(Species ~., method="rpart", data=training)
print(modFit$finalmodel)
print(modFit$finalModel)
plot(modFit$finalModel, uniform=TRUE)
test(modFit$finalModel, use.n=TRUE, all=TRUE, cesx=.8)
text(modFit$finalModel, use.n=TRUE, all=TRUE, cesx=.8)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
data <- segmentationOriginal
inTrain <- createDataPartition(y=data$Case, p=0.60,list=FALSE)
training <- data[inTrain, ]
testing <- data[-inTrain, ]
set.seed(125)
View(training)
testing <- subset(data, Case = "Test")
testing <- subset(data, Case == "Test")
training <- subset(data, Case == "train")
training <- subset(data, Case == "Train")
set.seed(125)
modelFit <- train(data$Class ~ ., method="glm", data=training)
modelFit <- train(data$Class ~ ., method="rpart", data=training)
View(training)
modelFit <- train(data$Class ~ ., method="rpart", data=training)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
training <- subset(data, Case == "Train")
testing <- subset(data, Case == "Test")
data <- segmentationOriginal
training <- subset(data, Case == "Train")
testing <- subset(data, Case == "Test")
set.seed(125)
modelFit <- train(data$Class ~ ., method="rpart", data=training)
modelFit <- train(Class ~ ., method="rpart", data=training)
install.packages("rattle")
library(rattle)
fancyRpartPlot(modelFit$finalModel)
fancyRpartPlot(modelFit$finalModel)
install.packages("rpart.plot")
fancyRpartPlot(modelFit$finalModel)
print(modelFit$finalModel)
predict(modelFit, newdata = testing)
a <-TotalIntench2 = 23,000; FiberWidthCh1 = 10; PerimStatusCh1=2
a <- TotalIntench2 = 23.000; FiberWidthCh1 = 10; PerimStatusCh1=2
predict(modelFit, newdata = TotalIntench2 = 23,000; FiberWidthCh1 = 10; PerimStatusCh1=2)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
data <- segmentationOriginal
training <- subset(data, Case == "Train")
testing <- subset(data, Case == "Test")
set.seed(125)
modelFit <- train(Class ~ ., method="rpart", data=training)
fancyRpartPlot(modelFit$finalModel)
library(AppliedPredictiveModeling)
install.packages(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
data(segmentationOriginal)
library(caret)
install.packages("segmentationOriginal")
install.packages("caret")
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
data <- segmentationOriginal
training <- subset(data, Case == "Train")
testing <- subset(data, Case == "Test")
set.seed(125)
modelFit <- train(Class ~ ., method="rpart", data=training)
install.packages("e1071")
modelFit <- train(Class ~ ., method="rpart", data=training)
install.packages("rattle")
library(rattle)
fancyRpartPlot(modelFit$finalModel)
install.packages("rpart.plot")
fancyRpartPlot(modelFit$finalModel)
TotalIntench2a <- 23.000
TotalIntench2a <- 23,000
TotalIntench2a <- 23000
FiberWidthCh1a <- 10
PerimStatusCh1 <- 2
as.dataset(TotalIntench2a,FiberWidthCh1a, PerimStatusCh1)
as.data.set(TotalIntench2a,FiberWidthCh1a, PerimStatusCh1)
as.data.frame(TotalIntench2a,FiberWidthCh1a, PerimStatusCh1)
as.data.frame(23000,10,2)
a <- as.data.frame(23000,10,2)
a <- as.data.frame(a,b,c)
a <- as.data.frame(c(23000,10,2) names=c("TotalIntench2", "FiberWidthCh1",PerimStatusCh")
a <- as.data.frame(c(23000,10,2), names=c("TotalIntench2", "FiberWidthCh1",PerimStatusCh")
)
)
dsno
/vds
vsdv
]
1
~
a <- as.data.frame(c(23000,10,2), names=c("TotalIntench2", "FiberWidthCh1","PerimStatusCh"))
View(a)
a <- as.data.frame(c(23000,50000,57000), colnames=c"TotalIntench2")
a <- as.data.frame(c(23000,50000,57000), colnames="TotalIntench2")
View(a)
b <- as.data.frame(c(10,10,8))
c <- as.data.frame(c(2,100,100))
cbind(a,b,c)
test <- cbind(a,b,c)
colnames(test) <- c("TotalIntench2", "FiberWidthCh1", "PerimStatusCh1")
View(test)
predict(modelFit,newdata=test)
View(training)
View(test)
print(modelFit$finalModel)
library(pgmm)
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
View(olive)
modelFit <- train(Area ~ ., method="rpart", data=olive)
newdata = as.data.frame(t(colMeans(olive)))
View(newdata)
predict(model, newdata)
predict(modelFit, newdata)
library(ElemStatLearn)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
modelFit <- train(chd ~ age+alcohol+obesity+tobacco+typea+ldl, method="glm",family="binomial",  data=trainSA)
prediction <- predict(modelFit, testSA)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass
missClass(trainSA$chd, predict(modelFit, trainSA))
missClass(testSA$chd, predict(model, testSA))
missClass(testSA$chd, predict(modelFit, testSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
data(vowel.train)
data(vowel.test)
summary(vowel.train)
summary(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
varImp(modFit)
modFit <- train(y~ .,data=vowel.train,method="rf",prox=TRUE)
varImp(modFit)
modFit <- train(y~ .,data=vowel.train,method="rf",prox=TRUE)
varImp(modFit)
modFit <- train(y~ .,data=vowel.train,method="rf",prox=FALSE)
varImp(modFit)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
summary(vowel.train)
summary(vowel.test)
vowel.train$y <-as.factor(vowel.train$y)
vowel.test$y <-as.factor(vowel.test$y)
set.seed(33833)
mod1 <- train(y ~.,method="rf",data=vowel.train)
library(caret)
mod1 <- train(y ~.,method="rf",data=vowel.train)
mod2 <- train(y ~.,method="glm", data=vowel.train)
mod2 <- train(y ~.,method="gbm", data=vowel.train)
pred1 <- predict(mod1,vowel.test)
pred2 <- predict(mod2,vowel.test)
cmrf <- confusionMatrix(pred1, vowel.test$y)
cmgbm <- confusionMatrix(pred2, vowel.test$y)
cmrf$overall['Accuracy']
cmgbm$overall['Accuracy']
predDF <- data.frame(pred1,pred2,y=vowel.test$y)
combModFit <- train(y ~.,data=predDF)
combPred <- predict(combModFit,predDF)
cmcomb <- confusionMatrix(predDF, vowel.test$y)
cmcomb <- confusionMatrix(combPred, vowel.test$y)
cmcomb$overall['Accuracy']
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
modrf <- train(diagnosis ~.,method="rf",data=training)
modgbm <- train(diagnosis ~.,method="gbm", data=training)
modgbm <- train(diagnosis ~.,method="lda", data=training)
modlda <- train(diagnosis ~.,method="lda", data=training)
modrf <- train(diagnosis ~.,method="rf",data=training)
modgbm <- train(diagnosis ~.,method="gbm", data=training)
modlda <- train(diagnosis ~.,method="lda", data=training)
predrf <- predict(modrf,testing)
predgbm <- predict(modgbm,testing)
predlda <- predict(modlda,testing)
cmrf <- confusionMatrix(predrf, testing$diagnosis)
cmgbm <- confusionMatrix(predgbm, testing$diagnosis)
cmlda <- confusionMatrix(predlda, testing$diagnosis)
comb <- data.frame(predrf,predgbm,predlda,diagnosis=testing$diagnosis)
combModFit <- train(diagnosis ~.method="rf",data=comb)
combPred <- predict(combModFit,testing)
combModFit <- train(diagnosis ~., method="rf",data=comb)
combPred <- predict(combModFit,testing)
cmcomb <- confusionMatrix(combPred,testing$diagnosis)
cmrf$overall['Accuracy']
cmgbm$overall['Accuracy']
cmlda$overall['Accuracy']
cmcob$overall['Accuracy']
cmcomb$overall['Accuracy']
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
?plot.enet
??plot.enet
set.seed(233)
lassoFit <- train( training$CompressiveStrength ~ ., method="lasso", data=training)
lassoPred <- predict(lassoFit,testing)
plot.enet(lassoFit$finalModel, xvar="penalty", use.color=T)
library(lubridate)
install.packages("lubricate")
getwd()
dat <- read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(lubridate)
install.packages("lubridate")
library(lubridate)
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
install.packages("forecast")
View(training)
View(training)
mod <- bats(tstrain)
fcast <- forecast.bats(mod, level=95, h=nrow(testing))
acc <- accuracy(fcast, testing$visitsTumblr)
library(forecast)
mod <- bats(tstrain)
fcast <- forecast.bats(mod, level=95, h=nrow(testing))
acc <- accuracy(fcast, testing$visitsTumblr)
count <- 0
for (i in 1:nrow(testing)) {
if (testing$visitsTumblr[i] > fcast$lower[i]) {
if(testing$visitsTumblr[i] < fcast$upper[i]) {
count <- count + 1}
}
}
count/nrow(testing)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
library(caret)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
library(e1071)
fit <- train(CompressiveStrength ~ ., data = training, method = "svmRadial")
fit <- train(CompressiveStrength ~ ., data = training, method = "svmRadial")
prediction <- predict(fit, testing)
accuracy(prediction, testing$CompressiveStrength)
vector("integer", 1)
vector("integer", 10)
vector("integer", 10, 1)
vector("logical", 10)
vector("complex", 10)
i
x <- 0+9
dim(x)
length(x)
x
x <- 0:9
dim(x)
length(x)
x <- a:g
x <- "a":"g"
x <- c("a","b", "a", "b")
class(x)
as.factor(x)
x <- factor(c("yes", "no", "yes"))
unclass(x)
x <- c(1, na, nan)
x <- c(1, "na", "nan")
is.na(x)
x <- c(1, NA, NaN)
is.na(x)
is.nan(x)
data <- read.csv("pml-training.csv", na.strings=c("NA","#DIV/0!",""))
test.or <- read.csv("pml-testing.csv", na.strings=c("NA","#DIV/0!",""))
library(caret)
getwd()
setwd("C:/Users/castor/Documents/github/machinelearnig_courseproject")
setwd("C:/Users/castor/Documents/GitHub/MachineLearning_CourseProject")
data <- read.csv("pml-training.csv", na.strings=c("NA","#DIV/0!",""))
test.or <- read.csv("pml-testing.csv", na.strings=c("NA","#DIV/0!",""))
library(caret)
na_test = sapply(data, function(x) {sum(is.na(x))})
table(na_test)
na_columns <- names(na_test[na_test > 19215])
data <- data[, !names(data) %in% na_columns]
test.or <- test.or[, !names(test.or) %in% na_columns]
